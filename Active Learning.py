# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17yHm9ZgnuOsmiPSSHN5zDn1DwyhgMahr
"""

import sklearn
import pandas as pd
import numpy as np
from sklearn import datasets
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.linear_model import LogisticRegression
from sklearn import svm
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
import keras
import scipy
from sklearn.cluster import KMeans
from keras.models import load_model
from sklearn.model_selection import train_test_split

dataset=keras.datasets.mnist.load_data(path="mnist.npz")

(x_train, y_train), (x_test, y_test)=dataset

def image_plot(image):
    plt.imshow(image)

def percentage_samples(percentage,X,y):
    total_lenght=X.shape[0]
    size_new=int((percentage*total_lenght)/100)
    X_new=X[:size_new]
    Y_new=y[:size_new]
    return X_new,Y_new

X_new,Y_new=percentage_samples(10,x_train,y_train)

model=keras.models.Sequential([keras.layers.Flatten(),keras.layers.Dense(6,activation="relu"),keras.layers.Dense(10,activation="softmax")])

model.compile(loss="sparse_categorical_crossentropy",optimizer="adam",metrics=["accuracy"])

history=model.fit(X_new/255.0,Y_new,epochs=5,validation_data=(x_test,y_test))

model.save(('my_model.h5'))
model1 = load_model('my_model.h5')

###uncertainity sampling with least confidence
def uncertainity_sampling_least_confident(Y_pred_probs,no_unlabeled_to_labeled):
    argsort=np.argsort(np.max(Y_pred_probs,axis=1))
    X_labels=argsort[:no_unlabeled_to_labeled]+6000 #sorts on the basis on minimum(max-confidence)
    #Y_label_to_added=Y_pred_probs[argsort[:no_unlabeled_to_labeled]]
    return X_labels

Y_probs=model.predict(x_train[6000:6100]/255.0)      #### giving 1000 data points and labeling 10 out of them

X_labels_to_add=uncertainity_sampling_least_confident(Y_probs,10)

print(X_labels_to_add)

#### uncertainity sampling  with marging samping
def uncertainity_sampling_margin_sampling(y_pred_probs,no_to_keep):
  y_probs_copy=np.copy(y_pred_probs)
  max_probs=np.max(y_pred_probs,axis=1)
  index_max_probs=np.argmax(y_pred_probs,axis=1)
  new_array=np.zeros((y_probs_copy.shape[0],9))
  for i in range(y_probs_copy.shape[0]):
    new_array[i]=np.delete(y_probs_copy[i],index_max_probs[i])
  second_max_probs=np.max(new_array,axis=1)
  final_array=max_probs-second_max_probs
  final_sort=np.argsort(final_array)
  final_indexs_to_return=final_sort[:no_to_keep]
  final_indexs_to_return+=6000
  return final_indexs_to_return

indexes_to_label=uncertainity_sampling_margin_sampling(Y_probs,10)

indexes_to_label

####uncertainity sampling with entropy
def uncertainity_sampling_entropy(y_probs,no_to_keep):
  list_to_return=np.argsort((-y_probs*np.log2(y_probs)).sum(axis=1))
  array_reversed=(list_to_return[::-1])
  final_index_to_return=array_reversed[:no_to_keep]
  final_index_to_return+=6000
  return final_index_to_return

labels_indexes=uncertainity_sampling_entropy(Y_probs,10)

labels_indexes

class Query_by_committee:
  def __init__(self):
    self.commitee1_svm = svm.SVC(decision_function_shape='ovo',probability=True)
    self.commitee2_rf=RandomForestClassifier(max_depth=2, random_state=0)
    self.commitee3_lr=LogisticRegression()
    self.commitee4_dtree = DecisionTreeClassifier(random_state=0)
    self.commitee5_nn=model
    self.predictions=None
    self.prediction_proba=None

  def to_predictions(self,X_fit,Y_fit,X_predict):
    X_new=X_fit.reshape((X_fit.shape[0],X_fit.shape[1]*X_fit.shape[2]))
    X_predict_new=X_predict.reshape((X_predict.shape[0],X_predict.shape[1]*X_predict.shape[2]))
    self.predictions=np.zeros((5,X_predict.shape[0]))
    self.commitee1_svm.fit(X_new,Y_fit)
    self.commitee2_rf.fit(X_new,Y_fit)
    self.commitee3_lr.fit(X_new,Y_fit)
    self.commitee4_dtree.fit(X_new,Y_fit)
    self.predictions[0]=np.argmax(self.commitee1_svm.predict_proba(X_predict_new),axis=1)
    self.predictions[1]=np.argmax(self.commitee2_rf.predict_proba(X_predict_new),axis=1)
    self.predictions[2]=np.argmax(self.commitee3_lr.predict_proba(X_predict_new),axis=1)
    self.predictions[3]=np.argmax(self.commitee4_dtree.predict_proba(X_predict_new),axis=1)
    self.predictions[4]=np.argmax(model.predict(X_predict),axis=1)


  def voting(self):
    voting_array=np.zeros((self.predictions.shape[1],10))
    for j in range(int(self.predictions.shape[1])):
      for i in range(5):
        voting_array[j][int(self.predictions[i][j])]+=1
    final_entropy_array=np.argsort((-voting_array*np.log2(voting_array)).sum(axis=1)) ##### applying vote entroy
    return (final_entropy_array,voting_array)
   
   
  def kl(self,p, q):
    """Kullback-Leibler divergence D(P || Q) for discrete distributions

    Parameters
    ----------
    p, q : array-like, dtype=float, shape=n
    Discrete probability distributions.
    """
    return np.sum(np.where(p != 0, p * np.log(p / q), 0))


  def kl_divergence(self,X_predict):
    X_predict_new=X_predict.reshape((X_predict.shape[0],X_predict.shape[1]*X_predict.shape[2]))
    kl_array=np.zeros((5,X_predict_new.shape[0]))
    self.prediction_proba=np.zeros((5,X_predict_new.shape[0],10))
    self.prediction_proba[0]=self.commitee1_svm.predict_proba(X_predict_new)
    self.prediction_proba[1]=self.commitee2_rf.predict_proba(X_predict_new)
    self.prediction_proba[2]=self.commitee3_lr.predict_proba(X_predict_new)
    self.prediction_proba[3]=self.commitee4_dtree.predict_proba(X_predict_new)
    self.prediction_proba[4]=self.commitee5_nn.predict(X_predict)
    prediction_mean=np.mean(self.prediction_proba,axis=0)
    for j in range(self.predictions.shape[1]):
      for i in range(5):
        kl_array[i][j]=self.kl(self.prediction_proba[i][j],prediction_mean[j])
    return kl_array

def calculating_index_list_greater(array,number):
  list=[]
  for i in range(array.shape[0]):
    if((array[i]<number).sum()!=10):
      list.append(i)
  return list
def calculating_index_list_smaller(array,number):
  list=[]
  for i in range(array.shape[0]):
    if((array[i]<number).sum()==10):
      list.append(i)
  return list
def is_1_there(array,no_1s):
  list=[]
  for i in range(array.shape[0]):
    if((array[i]==1).sum()==no_1s):
      list.append(i)
  return list

  ##dividing labels to query based on dissagrement 
  ### here we know total commitee members are 5 so  we will try to find disagremment pairs
  ##pairs possible are (1,4) ,(2,3) ,(2,1,1,1) ,(3,1,1),(1,1,1,1,1)and (2,1,2)
  ## 1st pair would be 1& 4 disagremment paris
def dataanalysis_Version_Space(version_space_array):
  total_indexes=np.arange(version_space_array.shape[0])
  copy_vs_array=np.copy(version_space_array)
  disagreement_with_4=calculating_index_list_greater(version_space_array,4)
  disagreement_with_4_array=version_space_array[disagreement_with_4]
  version_space_array_1=np.delete(copy_vs_array,np.array(disagreement_with_4),axis=0)###this array has all values <3
  new_list_indices=np.delete(total_indexes,disagreement_with_4)##new list of indices wrt to total containing all values <3 indices
  disagreement_with_3=calculating_index_list_greater(version_space_array_1,3)#### this includes all votes with 3 in it
  disagreement_with_3_array=version_space_array_1[disagreement_with_3]
  disagreement_with_3_wrt_total=new_list_indices[disagreement_with_3] ### gives actual indices  wrt original version_Space _array
  disagreement_with_1_1_3= is_1_there(disagreement_with_3_array,2)
  disagreement_with_1_1_3_wrt_total=disagreement_with_3_wrt_total[disagreement_with_1_1_3]### gives actual indices of pair(3,1,1) wrt original array
  disagreement_with_2_3_wrt_total=np.delete(disagreement_with_3_wrt_total,disagreement_with_1_1_3,axis=0) ##gives actual indices of (2,3) wrt to original_array
  version_space_array_2=np.delete(version_space_array_1,disagreement_with_3,axis=0) ### array which contains only votes<=2
  new_list_indices_1=np.delete(new_list_indices,disagreement_with_3)
  disagreement_with_1_1_1_2= is_1_there(version_space_array_2,3)
  disagreement_with_1_1_1_2_wrt_total=new_list_indices_1[disagreement_with_1_1_1_2] #### indices of pair  (1,1,1,2) w.rt total
  disagreement_with_2_1_2=is_1_there(version_space_array_2,1)
  disagreement_with_2_1_2_wrt_total=new_list_indices_1[disagreement_with_2_1_2]   ####indices of pair (1,2,2) w.r.t total
  disagreement_with_1_1_1_1_1=is_1_there(version_space_array_2,5)
  disagreement_with_1_1_1_1_1_wrt_total=new_list_indices_1[disagreement_with_1_1_1_1_1]
  return (disagreement_with_1_1_1_1_1_wrt_total,disagreement_with_1_1_1_2_wrt_total,disagreement_with_1_1_3_wrt_total,disagreement_with_2_1_2_wrt_total,disagreement_with_2_3_wrt_total,disagreement_with_4)

# Applying  k-means clustering aglorithm and calculation of benefits

#constructing the model
km = KMeans(n_clusters=10)
clustering_data = x_train[6000:27600]  #40% of data
km.fit(clustering_data.reshape((clustering_data.shape[0],clustering_data.shape[1]*clustering_data.shape[2])))
y_pred=km.predict(clustering_data.reshape((clustering_data.shape[0],clustering_data.shape[1]*clustering_data.shape[2])))

#Storing the clusters and their contents
clusters = {}
n = 6000
for item in y_pred:
  if item in clusters:
    clusters[item].append(n)
  else:
    clusters[item] = [n]
  n +=1

#Using 20% of data points from each cluster to label the points  
pred_clus = []
for item in clusters:
  pred = []
  n=0
  m=0
  mindex=0
  for i in clusters[item]:
    if(n>=0.2*len(clusters[item])):
      break 
    if(i%2==0):
      continue
    else: 
      n=n+1   
      pred.append(y_train[i])
  m = pred.count(0)
  mindex=0
  for j in range(1,9):
    if m < pred.count(j): 
      m =  pred.count(j)
      mindex = j    
  pred_clus.append(mindex)       
pred_clus  

#Calculating Accuracy
c=0
i=0
for item in clusters:
  for j in clusters[item]:
    if y_train[j]==pred_clus[i]:
       c=c+1
  i=i+1
acc=c/len(y_pred)
print("Accuracy: ",acc)

#Calculating clustering benefits
LabellingCostInit = 100*0.4*60000
LabellingTimeInit = 1*0.4*60000
LabellingCostClus = 0.2*100*0.4*60000
LabellingTimeClus = 0.2*1*0.4*60000
CostSaving = LabellingCostInit-LabellingCostClus
TimeSaving = LabellingTimeInit-LabellingTimeClus
print("Cost Saved is: Rs. ",CostSaving,)
print("Time Saved is: ",TimeSaving," hours")

y_train[6000:27600]

plt.imshow(x_train[6002])

### so now taking total remaining data adding 10% 20% 30% 40% data respectively and analyising different query strategies so
##1 querying uncertaininty sampling least confidence

Y_probs_total=model1.predict(x_train[6000:]/255.0)
to_label10=uncertainity_sampling_least_confident(Y_probs_total,6000)#20%
to_label20=uncertainity_sampling_least_confident(Y_probs_total,12000)#30%
to_label30=uncertainity_sampling_least_confident(Y_probs_total,18000)#40%

### now fiting through new data
model1.fit(x_train[to_label10]/255.0,y_train[to_label10],validation_data=(x_test,y_test),epochs=4)

model2 = load_model('my_model.h5')
model3 = load_model('my_model.h5')
model4 = load_model('my_model.h5')
model5 = load_model('my_model.h5')

model2.fit(x_train[to_label20]/255.0,y_train[to_label20],validation_data=(x_test,y_test),epochs=5)   ##### as we can see the model training accuracy is low as it is having problem in training these datasets but val_accuracy is increasing quite good

model3.fit(x_train[to_label30]/255.0,y_train[to_label30],validation_data=(x_test,y_test),epochs=5)

##2 querying uncertaininty sampling margin sampling
Y_probs_total_m=model1.predict(x_train[6000:]/255.0)
to_label10_m=uncertainity_sampling_margin_sampling(Y_probs_total_m,6000)#20%
to_label20_m=uncertainity_sampling_margin_sampling(Y_probs_total_m,12000)#30%
to_label30_m=uncertainity_sampling_margin_sampling(Y_probs_total_m,18000)#40%

model6 = load_model('my_model.h5')
model7 = load_model('my_model.h5')
model8 = load_model('my_model.h5')

model6.fit(x_train[to_label10_m]/255.0,y_train[to_label10_m],validation_data=(x_test,y_test),epochs=5)

model7.fit(x_train[to_label20_m]/255.0,y_train[to_label20_m],validation_data=(x_test,y_test),epochs=5)

model8.fit(x_train[to_label30_m]/255.0,y_train[to_label30_m],validation_data=(x_test,y_test),epochs=5)

##3 querying uncertaininty sampling margin sampling
Y_probs_total_e=model1.predict(x_train[6000:]/255.0)
to_label10_e=uncertainity_sampling_entropy(Y_probs_total_e,6000)#20%
to_label20_e=uncertainity_sampling_entropy(Y_probs_total_e,12000)#30%
to_label30_e=uncertainity_sampling_entropy(Y_probs_total_e,18000)#40%

model9 = load_model('my_model.h5')
model10 = load_model('my_model.h5')
model11 = load_model('my_model.h5')

model9.fit(x_train[to_label10_e]/255.0,y_train[to_label10_e],validation_data=(x_test,y_test),epochs=5)

model10.fit(x_train[to_label20_e]/255.0,y_train[to_label20_e],validation_data=(x_test,y_test),epochs=5)

model11.fit(x_train[to_label30_e]/255.0,y_train[to_label30_e],validation_data=(x_test,y_test),epochs=5)

###### now after this we will try to fit the using Query_by_committe this willl take really long please be patient
Query1=Query_by_committee()
Query1.to_predictions(X_new/255.0,Y_new,(x_train[6000:]/255.0))

entropy_array,voting_array=Query1.voting()

new_voting_array=np.copy(voting_array)
index_to_be_kept=[]
for i in range(new_voting_array.shape[0]):
  if((new_voting_array[i]<5).sum()==10):
    index_to_be_kept.append(i)

version_space_array_indexes=index_to_be_kept
version_space_array=voting_array[index_to_be_kept]

version_space_array.shape

##### Total no. of data points out of 54,000 unlabeled points are 26917 points are part of version space
entropy_array+=6000

##### so choosing percentages of points from entropy array to form commitee to query
to_label10_ce=entropy_array[-6000:][::-1]## total 20% to fit with
to_label20_ce=entropy_array[-12000:][::-1] ### total 30% to fit  with
to_label30_ce=entropy_array[-18000:][::-1]### total 40% to fit with

model12 = load_model('my_model.h5')
model13 = load_model('my_model.h5')
model14 = load_model('my_model.h5')

voting_array[53999]

to_label10_ce.shape

model12.fit(x_train[to_label10_ce]/255.0,y_train[to_label10_ce],validation_data=(x_test,y_test),epochs=5)



model13.fit(x_train[to_label20_ce]/255.0,y_train[to_label20_ce],validation_data=(x_test,y_test),epochs=5)

model14.fit(x_train[to_label30_ce]/255.0,y_train[to_label30_ce],validation_data=(x_test,y_test),epochs=5)

###now we train the model using version_space
version_space_array.shape

tuple1=dataanalysis_Version_Space(version_space_array)
version_space_array_indexes=np.array(version_space_array_indexes)     ### as it was in list so converting it to array

(disagreement_with_1_1_1_1_1,disagreement_with_1_1_1_2,disagreement_with_1_1_3,disagreement_with_2_1_2,disagreement_with_2_3,disagreement_with_4)=tuple1
disagreement_with_4=version_space_array_indexes[disagreement_with_4] ###this is to make it wrt original as after this these indices will be original model example variab;e
disagreement_with_1_1_1_2=version_space_array_indexes[disagreement_with_1_1_1_2]
disagreement_with_1_1_1_1_1=version_space_array_indexes[disagreement_with_1_1_1_1_1]
disagreement_with_1_1_3=version_space_array_indexes[disagreement_with_1_1_3]
disagreement_with_2_1_2=version_space_array_indexes[disagreement_with_2_1_2]
disagreement_with_2_3=version_space_array_indexes[disagreement_with_2_3]

disagreement_with_4+=6000
disagreement_with_2_3+=6000
disagreement_with_2_1_2+=6000
disagreement_with_1_1_3+=6000
disagreement_with_1_1_1_2+=6000
disagreement_with_1_1_1_1_1+=6000

model15 = load_model('my_model.h5')
model16 = load_model('my_model.h5')
model17 = load_model('my_model.h5')
model18 =  load_model('my_model.h5')
model19 = load_model('my_model.h5')

##### as we know to reduce the version space most we will choose the labels with most dissagrement 
#### so order for fitting the votes would be (1,1,1,1,1) then (1,1,1,2) then (2,1,2) then (1,1,3) then (2,3) then if 40% are not been covered up we will label (1,4) pair

disagreement_with_1_1_1_1_1

model15.fit(x_train[disagreement_with_1_1_1_1_1]/255.0,y_train[disagreement_with_1_1_1_1_1],validation_data=(x_test,y_test),epochs=5)    ##### as the results show training  accuracy is horrrible these may be the outlier points like 1 looking like 2 or something

model15.fit(x_train[disagreement_with_1_1_1_2]/255.0,y_train[disagreement_with_1_1_1_2],validation_data=(x_test,y_test),epochs=5)

model15.fit(x_train[disagreement_with_2_1_2]/255.0,y_train[disagreement_with_2_1_2],validation_data=(x_test,y_test),epochs=5)     ######

model15.fit(x_train[disagreement_with_1_1_3]/255.0,y_train[disagreement_with_1_1_3],validation_data=(x_test,y_test),epochs=5)

model15.fit(x_train[disagreement_with_2_3]/255.0,y_train[disagreement_with_2_3],validation_data=(x_test,y_test),epochs=5)

model15.fit(x_train[disagreement_with_4[:5000]]/255.0,y_train[disagreement_with_4[:5000]],validation_data=(x_test,y_test),epochs=5) #######as the results can see we have trained for about 130000 images and it is giving us a val accuracy of 0.89 which is really amaaazing as just about 30% of labels have been increased and  a much better perfomance is been observed

model21=load_model('my_model.h5')

model21.fit(x_train[6000:]/255.0,y_train[6000:],validation_data=(x_test,y_test),epochs=5)             #### training the model fully just gives us a val accuracy of 0.8604 although training a model through active learning give val accuracy of 0.8604 so thus a lot less labels required

def stream_based_learning(y_probs,threshold):
  new_dataset_to_label_idx=[]
  count=0
  for i in range(x_train[6000:].shape[0]):
    if (-y_probs[i]*np.log2(y_probs[i])).sum()>threshold:
      new_dataset_to_label_idx.append(i)
      count+=1
    if count==12000:
      return new_dataset_to_label_idx
  return new_dataset_to_label_idx

y_probs=model.predict(x_train[6000:]/255.0)  
print((-y_probs*np.log2(y_probs)).sum(axis=1).max())  
dataset_to_get_labeled=stream_based_learning(y_probs,1.5)

len(dataset_to_get_labeled)

dataset_to_get_labeled=np.array(dataset_to_get_labeled)

dataset_to_get_labeled+=6000

model22=load_model('my_model.h5')

model22.fit(x_train[dataset_to_get_labeled]/255.0,y_train[dataset_to_get_labeled],validation_data=(x_test,y_test),epochs=5)

kl_array=Query1.kl_divergence(x_train[6000:]/255.0)#####kl divergence, this will take some time

prob=Query1.prediction_proba

kl_array_max=np.max(kl_array,axis=0)

idxes_to_label=np.argsort(kl_array_max)

idxes_to_label+=6000

kl_div_10=idxes_to_label[-6000:][::-1]
kl_div_20=idxes_to_label[-12000:][::-1]
kl_div_30=idxes_to_label[-18000:][::-1]
kl_div_40=idxes_to_label[-24000:][::-1]

model27=load_model('my_model.h5')
model28=load_model('my_model.h5')
model29=load_model('my_model.h5')
model30=load_model('my_model.h5')

model27.fit(x_train[kl_div_10]/255.0,y_train[kl_div_10],validation_data=(x_test,y_test),epochs=5)

model28.fit(x_train[kl_div_20]/255.0,y_train[kl_div_20],validation_data=(x_test,y_test),epochs=5)

model29.fit(x_train[kl_div_30]/255.0,y_train[kl_div_30],validation_data=(x_test,y_test),epochs=5)

model30.fit(x_train[kl_div_40]/255.0,y_train[kl_div_40],validation_data=(x_test,y_test),epochs=5)

###### making a random dataset of additional
random_int=np.random.randint(6000,60000,size=(12000))

random_int.shape

model49=load_model('my_model.h5')

model49.fit(x_train[random_int]/255.0,y_train[random_int],validation_data=(x_test,y_test),epochs=5)

